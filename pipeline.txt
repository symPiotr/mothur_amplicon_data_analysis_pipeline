#######################################
############## OUR DATA ###############

>>> 230ish amplicon libraries, for different genes (insect mitochondrial - COI, 16S rRNA; bacterial - 16S rRNA, different regions), for different insects or groups of insects. Different amplicon types within library.
>>> Libraries prepared using custom two-step PCR (first round - template-specific PCR; second round - indexing), following a modified Meyer & Kircher 2010 protocol.
>>> Pooled libraries sequenced on a shared MiSeq v3 lane (2x300bp reads) at the Institute of Environmental Sciences
>>> Data available on the IES cluster: /mnt/matrix/symbio/raw_data/20191109_MiSeq_first_run/


#######################################
####### THE PIPELINE - SUMMARY ########

For selected samples, we:
	Copy reads to a working directory
	Trim reads (trim_galore)
	Assemble reads into contigs
	Quality-screen reads
	Select unique sequences and compute count table
	Discard rare unique seqs
	Align reads to a reference, discard those that didn't align
	[16S] Screen for chimeras
	[16S] Assign taxonomy
	Compute distance matrix, pick OTUs
	Prepare OTU tables

Example data that I am starting with: three libraries for Macrosteles laevis leafhopper individuals, prepped by Sandra and Monika. They attempted to amplify three genes:
	Insect mitochondrial COI (primers BF3 & BR2)
	Insect mitochondrial 16S rRNA (primers Chiar16SF and Chiar16SR, Marquina et al. 2018)
	Bacterial 16S rRNA (primers 515F and 806R)
... but mito16S didn't amplify because of a critical mismatch in one of the primers. Then, these libraries contain the mixture of two products.


#######################################
######## SETTING UP WORKSPACE #########

### Login to the cluster!
ssh user.name@149.156.165.80 <- leskowiec

### Create working directory, perhaps in your home directory. Go there.
cd ~
mkdir amplicon_analyses
cd amplicon_analyses
mkdir 20191112_test
cd 20191112_test

### Select files for analysis.
### Mothur can work with gzip-compressed files, but the last time I had some issues.
### Hence, you might choose to copy selected files, for example to raw_reads folder in your work-dir, and uncompress them there.
### You may or may not want to rename the files.

mkdir raw_reads
cd raw_reads

cp /home/piotr.lukasik/symbio/raw_data/20191109_MiSeq_first_run/S-BTW1_S213_L001_R1_001.fastq.gz ./S-BTW1_R1.fastq.gz
cp /home/piotr.lukasik/symbio/raw_data/20191109_MiSeq_first_run/S-BTW1_S213_L001_R2_001.fastq.gz ./S-BTW1_R2.fastq.gz
cp /home/piotr.lukasik/symbio/raw_data/20191109_MiSeq_first_run/S-BTW2_S210_L001_R1_001.fastq.gz ./S-BTW2_R1.fastq.gz
cp /home/piotr.lukasik/symbio/raw_data/20191109_MiSeq_first_run/S-BTW2_S210_L001_R2_001.fastq.gz ./S-BTW2_R2.fastq.gz
cp /home/piotr.lukasik/symbio/raw_data/20191109_MiSeq_first_run/S-BTW3_S207_L001_R1_001.fastq.gz ./S-BTW3_R1.fastq.gz
cp /home/piotr.lukasik/symbio/raw_data/20191109_MiSeq_first_run/S-BTW3_S207_L001_R2_001.fastq.gz ./S-BTW3_R2.fastq.gz

gunzip *
cd ..

### Check cluster usage. Make sure it's not being used too heavily!
### My favorite tool is htop:
htop
    # Press q to quit!

### Start screen --- an interactive session which helps ensure that a broken network connection won't interrupt your analyses
screen -S mothur_session
    # Other useful commands:
	# Ctrl+A+D --- leave session;
	# screen -r <session_name OR session#> --- rejoin session;
	# screen -ls --- list running sessions;
	# Ctrl+A, then type :quit --- kill session you are connected to.




#######################################
#### MOTHUR - SETUP, QC, TRIMMING #####

### Within a screen, start mothur!
mothur

### Set working directory
set.dir(input=~/amplicon_analyses/20191112_test, output=~/amplicon_analyses/20191112_test)

### Assemble forward and reverse reads into contigs
### First, create the file with a list of libraries and files.
make.file(inputdir=~/amplicon_analyses/20191112_test/raw_reads, type=fastq, prefix=ML)

### You may want to see how the file looks, and edit it.
system(cat ~/amplicon_analyses/20191112_test/ML.files)
    # Hopefully, lines will go like this ---
        # S-BTW1	S-BTW1_R1.fastq	S-BTW1_R2.fastq
    # You may want to edit your files manually to avoid dashes within sample names, as this would create problems downstream.
    # In TextWrangler, File > Open from FTP/SFTP Server;
    # Then Search > Replace; Select "grep" as the option;
    # Then ^S-BTW >>> S_BTW

### Join forward and reverse reads into contigs!
make.contigs(file=ML.files)
    # Output File Names: 
	# /home/piotr.lukasik/amplicon_analyses/20191112_test/ML.trim.contigs.fasta
	# /home/piotr.lukasik/amplicon_analyses/20191112_test/ML.scrap.contigs.fasta
	# /home/piotr.lukasik/amplicon_analyses/20191112_test/ML.contigs.report
	# /home/piotr.lukasik/amplicon_analyses/20191112_test/ML.contigs.groups
    # let's look at them!

### Re-set working directory 
set.dir(input=~/amplicon_analyses/20191112_test, output=~/amplicon_analyses/20191112_test)

### Let's disconnect from the screen where mothur runs
    # Ctrl+a+d

### And look at a subset of original reads and the assembled contigs. 
head -20 raw_reads/S-BTW1_R1.fastq
    # displays the first five R1 reads ...
head -20 raw_reads/S-BTW1_R2.fastq
    # displays the first five R2 reads ...
head -20 ML.trim.contigs.fasta
    # displays the first five contigs.

### Paste reads into CodonCode Aligner, assemble reads + contigs corresponding to the same read pair ... not great.
### Mothur uses read quality information to a limited extent; the information that certain regions are of low quality becomes lost.
### But a bigger problem is that for our 16S rRNA v4 contigs, reads are longer than the contigs - and so they are reading into the adapter.
### It would be hard to deal with. A possible approach would be trimming the reads --- eliminating the last 20-50 bases from each.
### We can do this using software called trim_galore, also in our path.

### Trim reads using trim_galore:
cd raw_reads
trim_galore --dont_gzip --hardtrim5 250 *fastq

### In TextWrangler, edit the sample-file info (ML.files) so that the samples are linked to the newly trimmed fastq files:
### Also, we have been changing the input directory more than once, which can create confusion;
### Hence, it might be safer if in your ML.files you specify the full path to your reads!
    # Hopefully, lines will go like this ---
        #S_BTW1	~/amplicon_analyses/20191112_test/raw_reads/S-BTW1_R1.250bp_5prime.fq	~/amplicon_analyses/20191112_test/raw_reads/S-BTW1_R2.250bp_5prime.fq


### get back to mothur
make.contigs(file=ML.files)


summary.seqs(fasta=current)


######## Quality-trimming sequences
trim.seqs(fasta=ML.trim.contigs.fasta, group=ML.contigs.groups, oligos=primers_to_trim.oligos, minlength=250, maxlength=500, maxambig=0, maxhomop=10, pdiffs=2)

""" primers_to_trim.oligos
#COI - BF3, BR2
forward CCHGAYATRGCHTTYCCHCG
reverse TCDGGRTGNCCRAARAAYCA

#16S-mito - Chiar16SF, Chiar16SR
forward ARTYCAACATCGRGGTC
reverse CYGTRCDAAGGTAGCAWA

#16Sbact - 515F, 806R
forward GTGYCAGCMGCCGCGGTAA
reverse GGACTACNVGGGTWTCTAAT
"""

######## Extracting quality-trimmed sequences
# list.seqs(fasta=ML.trim.contigs.trim.fasta)
# get.seqs(accnos=ML.trim.contigs.trim.accnos, group=ML.contigs.groups)
list.seqs(fasta=current)
get.seqs(accnos=current, group=current)

######## Get basic info about sequences!
summary.seqs(fasta=current)
count.groups(fasta=current)

####### Selecting specific libraries for analysis from larger datasets ?
# get.groups(group=ML.contigs.pick.groups, fasta=ML.trim.contigs.trim.fasta, groups=PL301-PL302-TETLON-...)

####### Merging files?
# merge.files(input=samples_first_run.trim.contigs.trim.fasta-samples_2nd_run.trim.contigs.trim.fasta, output=populations.fasta)
# merge.files(input=samples_first_run.contigs.pick.groups-samples_2nd_run.trim.contigs.trim.groups, output=populations.groups)



####### Pick unique sequences
unique.seqs(fasta=current)

####### Generate count_table = a unique sequence table
count.seqs(name=current, group=current)

summary.seqs(fasta=ML.trim.contigs.trim.unique.fasta)
summary.seqs(fasta=ML.trim.contigs.trim.unique.fasta, count=ML.trim.contigs.trim.count_table)



####### Discard unique genotypes present only once in the dataset (singletons)
split.abund(fasta=ML.trim.contigs.trim.unique.fasta, count=ML.trim.contigs.trim.count_table, cutoff=1)

summary.seqs(fasta=current, count=current)



######## Align sequences against a MLAE mitogenome!
#####
align.seqs(fasta=ML.trim.contigs.trim.unique.abund.fasta, reference=references/mito_MLAE.fasta, processors=16)
   # COI expected: 2578-2995?
   # 16S expected: 13487-13825

######## See how they aligned, removing unaligned
summary.seqs(fasta=ML.trim.contigs.trim.unique.abund.align)
screen.seqs(fasta=ML.trim.contigs.trim.unique.abund.align, count=ML.trim.contigs.trim.abund.count_table, start=2578, end=2995, minlength=400)

summary.seqs(fasta=current, count=current)
count.groups(count=current)

filter.seqs(fasta=current, vertical=T, trump=.)

######## Simplify file names
system(mv ./ML.trim.contigs.trim.abund.good.count_table ML_COI.count_table)
system(mv ./ML.trim.contigs.trim.unique.abund.good.filter.fasta ML_COI.fasta)

######## Compute distance matrix, cluster, construct summary tables
dist.seqs(fasta=ML_COI.fasta, processors=16, cutoff=0.05)
cluster(column=current, count=ML_COI.count_table, cutoff=0.03, method=average)
bin.seqs(list=current, fasta=current, label=0.01)
make.shared(list=current,count=current,label=0.01)






######## Align 16S sequences against a SILVA db
align.seqs(fasta=ML.trim.contigs.trim.unique.abund.fasta, reference=/mnt/matrix/symbio/db/silva.seed_v132.align, processors=24)


summary.seqs(fasta=ML.trim.contigs.trim.unique.abund.align)
screen.seqs(fasta=ML.trim.contigs.trim.unique.abund.align, count=ML.trim.contigs.trim.abund.count_table, start=13862, end=23444, minlength=220)

filter.seqs(fasta=current, vertical=T, trump=.)

unique.seqs(fasta=ML.trim.contigs.trim.unique.abund.good.filter.fasta, count=ML.trim.contigs.trim.abund.good.count_table)
    # ML.trim.contigs.trim.unique.abund.good.filter.count_table
    # ML.trim.contigs.trim.unique.abund.good.filter.unique.fasta


######## Identify and remove chimaeric sequences using UChime
chimera.uchime(fasta=ML.trim.contigs.trim.unique.abund.good.filter.unique.fasta, reference=self, count=ML.trim.contigs.trim.unique.abund.good.filter.count_table, dereplicate=f, mindiv=0.35, processors=24, minh=0.5, xn=3)
remove.seqs(accnos=current, fasta=current, count=current)


######## Classify
classify.seqs(fasta=current, count=current, reference=/mnt/matrix/symbio/db/silva.seed_v132.align, taxonomy=/mnt/matrix/symbio/db/silva.seed_v132.tax, cutoff=80)

remove.lineage(fasta=current, count=current, taxonomy=current, taxon=Chloroplast-Mitochondria-unknown-Archaea-Eukaryota)

summary.tax(taxonomy=current, count=current)


######## Simplify file names
system(mv ML.trim.contigs.trim.unique.abund.good.filter.unique.pick.pick.fasta ML_16S.fasta)
system(mv ML.trim.contigs.trim.unique.abund.good.filter.pick.pick.count_table ML_16S.count_table)
system(mv ML.trim.contigs.trim.unique.abund.good.filter.unique.pick.seed_v132.wang.pick.taxonomy ML_16S.taxonomy)

######## Compute distance matrix, cluster, construct summary tables
dist.seqs(fasta=ML_16S.fasta, processors=24, cutoff=0.05)
cluster(column=current, count=ML_16S.count_table, cutoff=0.03, method=average)
bin.seqs(list=current, fasta=current, label=0.01)
make.shared(list=current,count=current,label=0.01)






